

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Using find_MAP on models with discrete variables &mdash; PyMC3 3.0.rc1 documentation</title>
  

  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  

  

  
    <link rel="top" title="PyMC3 3.0.rc1 documentation" href="../index.html"/> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> PyMC3
          

          
          </a>

          
            
            
              <div class="version">
                3.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <ul>
<li class="toctree-l1"><a class="reference internal" href="../getting_started.html">Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api.html">API Reference</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../index.html">PyMC3</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          

 



<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../index.html">Docs</a> &raquo;</li>
      
    <li>Using <code class="docutils literal"><span class="pre">find_MAP</span></code> on models with discrete variables</li>
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/notebooks/discrete_find_MAP.txt" rel="nofollow"> View page source</a>
          
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput,
div.nbinput > div,
div.nbinput div[class^=highlight],
div.nbinput div[class^=highlight] pre,
div.nboutput,
div.nboutput > div,
div.nboutput div[class^=highlight],
div.nboutput div[class^=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput div[class^=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput,
div.nboutput {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
}

/* input container */
div.nbinput {
    padding-top: 5px;
}

/* last container */
div.nblast {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput > :first-child pre {
    color: #303F9F;
}

/* output prompt */
div.nboutput > :first-child pre {
    color: #D84315;
}

/* all prompts */
div.nbinput > :first-child[class^=highlight],
div.nboutput > :first-child[class^=highlight],
div.nboutput > :first-child {
    min-width: 11ex;
    padding-top: 0.4em;
    padding-right: 0.4em;
    text-align: right;
    flex: 0;
}

/* input/output area */
div.nbinput > :nth-child(2)[class^=highlight],
div.nboutput > :nth-child(2),
div.nboutput > :nth-child(2)[class^=highlight] {
    padding: 0.4em;
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}

/* input area */
div.nbinput > :nth-child(2)[class^=highlight] {
    border: 1px solid #cfcfcf;
    border-radius: 2px;
    background: #f7f7f7;
}

/* override MathJax center alignment in output cells */
div.nboutput div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.pngmath center alignment in output cells */
div.nboutput div.math p {
    text-align: left;
}

/* standard error */
div.nboutput  > :nth-child(2).stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-bold { font-weight: bold; }

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast,
.nboutput.nblast {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast + .nbinput {
    margin-top: -19px;
}

/* nice headers on first paragraph of info/warning boxes */
.admonition .first {
    margin: -12px;
    padding: 6px 12px;
    margin-bottom: 12px;
    color: #fff;
    line-height: 1;
    display: block;
}
.admonition.warning .first {
    background: #f0b37e;
}
.admonition.note .first {
    background: #6ab0de;
}
.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}
</style>
<div class="section" id="Using-find_MAP-on-models-with-discrete-variables">
<h1>Using <code class="docutils literal"><span class="pre">find_MAP</span></code> on models with discrete variables<a class="headerlink" href="#Using-find_MAP-on-models-with-discrete-variables" title="Permalink to this headline">Â¶</a></h1>
<p>Maximum a posterior(MAP) estimation, can be difficult in models which
have discrete stochastic variables. Here we demonstrate the problem with
a simple model, and present a few possible work arounds.</p>
<div class="nbinput nblast container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [1]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">pymc3</span> <span class="kn">as</span> <span class="nn">mc</span>
</pre></div>
</div>
</div>
<p>We define a simple model of a survey with one data point. We use a
<span class="math">\(Beta\)</span> distribution for the <span class="math">\(p\)</span> parameter in a binomial. We
would like to know both the posterior distribution for p, as well as the
predictive posterior distribution over the survey parameter.</p>
<div class="nbinput container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [2]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">alpha</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">beta</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">yes</span> <span class="o">=</span> <span class="mi">15</span>

<span class="k">with</span> <span class="n">mc</span><span class="o">.</span><span class="n">Model</span><span class="p">()</span> <span class="k">as</span> <span class="n">model</span><span class="p">:</span>
    <span class="n">p</span> <span class="o">=</span> <span class="n">mc</span><span class="o">.</span><span class="n">Beta</span><span class="p">(</span><span class="s1">&#39;p&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
    <span class="n">surv_sim</span> <span class="o">=</span> <span class="n">mc</span><span class="o">.</span><span class="n">Binomial</span><span class="p">(</span><span class="s1">&#39;surv_sim&#39;</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">)</span>
    <span class="n">surv</span> <span class="o">=</span> <span class="n">mc</span><span class="o">.</span><span class="n">Binomial</span><span class="p">(</span><span class="s1">&#39;surv&#39;</span><span class="p">,</span> <span class="n">n</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">,</span> <span class="n">observed</span><span class="o">=</span><span class="n">yes</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast container">
<div class="container">
</div>
<div class="stderr container">
<div class="highlight"><pre>
Applied logodds-transform to p and added transformed p_logodds_ to model.
</pre></div></div>
</div>
<p>First let&#8217;s try and use <code class="docutils literal"><span class="pre">find_MAP</span></code>.</p>
<div class="nbinput container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [3]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="k">with</span> <span class="n">model</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="n">mc</span><span class="o">.</span><span class="n">find_MAP</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast container">
<div class="container">
</div>
<div class="container">
<div class="highlight"><pre>
{&#39;surv_sim&#39;: array(10), &#39;p_logodds_&#39;: array(0.42285684671251805)}
</pre></div></div>
</div>
<p><code class="docutils literal"><span class="pre">find_map</span></code> defaults to find the MAP for only the continuous variables
we have to specify if we would like to use the discrete variables.</p>
<div class="nbinput container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [4]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="k">with</span> <span class="n">model</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="n">mc</span><span class="o">.</span><span class="n">find_MAP</span><span class="p">(</span><span class="nb">vars</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">vars</span><span class="p">,</span> <span class="n">disp</span><span class="o">=</span><span class="bp">True</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast container">
<div class="container">
</div>
<div class="container">
<div class="highlight"><pre>
{&#39;surv_sim&#39;: array(14), &#39;p_logodds_&#39;: array(0.7884573537909452)}
</pre></div></div>
</div>
<p>We set the <code class="docutils literal"><span class="pre">disp</span></code> variable to display a warning that we are using a
non-gradient minimization technique, as discrete variables do not give
much gradient information. To demonstrate this, if we use a gradient
based minimization, <code class="docutils literal"><span class="pre">fmin_bfgs</span></code>, with various starting points we see
that the map does not converge.</p>
<div class="nbinput container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [5]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="k">with</span> <span class="n">model</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">s</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;p&#39;</span><span class="p">:</span><span class="mf">0.5</span><span class="p">,</span> <span class="s1">&#39;surv_sim&#39;</span><span class="p">:</span><span class="n">i</span><span class="p">}</span>
        <span class="n">map_est</span> <span class="o">=</span> <span class="n">mc</span><span class="o">.</span><span class="n">find_MAP</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="n">s</span><span class="p">,</span> <span class="nb">vars</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">vars</span><span class="p">,</span> <span class="n">fmin</span><span class="o">=</span><span class="n">mc</span><span class="o">.</span><span class="n">starting</span><span class="o">.</span><span class="n">optimize</span><span class="o">.</span><span class="n">fmin_bfgs</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;surv_sim: </span><span class="si">%i</span><span class="s1">-&gt;</span><span class="si">%i</span><span class="s1">, p: </span><span class="si">%f</span><span class="s1">-&gt;</span><span class="si">%f</span><span class="s1">, LogP:</span><span class="si">%f</span><span class="s1">&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">s</span><span class="p">[</span><span class="s1">&#39;surv_sim&#39;</span><span class="p">],</span>
                                                      <span class="n">map_est</span><span class="p">[</span><span class="s1">&#39;surv_sim&#39;</span><span class="p">],</span>
                                                      <span class="n">s</span><span class="p">[</span><span class="s1">&#39;p&#39;</span><span class="p">],</span>
                                                      <span class="n">map_est</span><span class="p">[</span><span class="s1">&#39;p&#39;</span><span class="p">],</span>
                                                      <span class="n">model</span><span class="o">.</span><span class="n">logpc</span><span class="p">(</span><span class="n">map_est</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast container">
<div class="container">
</div>
<div class="container">
<div class="highlight"><pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">KeyError</span>                                  Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-5-299cdf766633&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">      2</span>     <span class="ansi-green-fg">for</span> i <span class="ansi-green-fg">in</span> range<span class="ansi-blue-fg">(</span>n<span class="ansi-blue-fg">+</span><span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">      3</span>         s <span class="ansi-blue-fg">=</span> <span class="ansi-blue-fg">{</span><span class="ansi-blue-fg">&#39;p&#39;</span><span class="ansi-blue-fg">:</span><span class="ansi-cyan-fg">0.5</span><span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">&#39;surv_sim&#39;</span><span class="ansi-blue-fg">:</span>i<span class="ansi-blue-fg">}</span>
<span class="ansi-green-fg">----&gt; 4</span><span class="ansi-red-fg">         </span>map_est <span class="ansi-blue-fg">=</span> mc<span class="ansi-blue-fg">.</span>find_MAP<span class="ansi-blue-fg">(</span>start<span class="ansi-blue-fg">=</span>s<span class="ansi-blue-fg">,</span> vars<span class="ansi-blue-fg">=</span>model<span class="ansi-blue-fg">.</span>vars<span class="ansi-blue-fg">,</span> fmin<span class="ansi-blue-fg">=</span>mc<span class="ansi-blue-fg">.</span>starting<span class="ansi-blue-fg">.</span>optimize<span class="ansi-blue-fg">.</span>fmin_bfgs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">      5</span>         print(&#39;surv_sim: %i-&gt;%i, p: %f-&gt;%f, LogP:%f&#39;%(s[&#39;surv_sim&#39;],
<span class="ansi-green-intense-fg ansi-bold">      6</span>                                                       map_est<span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">&#39;surv_sim&#39;</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">,</span>

<span class="ansi-green-fg">/home/wiecki/working/projects/pymc/pymc3/tuning/starting.py</span> in <span class="ansi-cyan-fg">find_MAP</span><span class="ansi-blue-fg">(start, vars, fmin, return_raw, model, *args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">     82</span>     <span class="ansi-green-fg">if</span> <span class="ansi-blue-fg">&#39;fprime&#39;</span> <span class="ansi-green-fg">in</span> getargspec<span class="ansi-blue-fg">(</span>fmin<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">.</span>args<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">     83</span>         r = fmin(logp_o, bij.map(
<span class="ansi-green-fg">---&gt; 84</span><span class="ansi-red-fg">             start), fprime=grad_logp_o, *args, **kwargs)
</span><span class="ansi-green-intense-fg ansi-bold">     85</span>     <span class="ansi-green-fg">else</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">     86</span>         r <span class="ansi-blue-fg">=</span> fmin<span class="ansi-blue-fg">(</span>logp_o<span class="ansi-blue-fg">,</span> bij<span class="ansi-blue-fg">.</span>map<span class="ansi-blue-fg">(</span>start<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/home/wiecki/working/projects/pymc/pymc3/blocking.py</span> in <span class="ansi-cyan-fg">map</span><span class="ansi-blue-fg">(self, dpt)</span>
<span class="ansi-green-intense-fg ansi-bold">     50</span>         apt <span class="ansi-blue-fg">=</span> np<span class="ansi-blue-fg">.</span>empty<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>ordering<span class="ansi-blue-fg">.</span>dimensions<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     51</span>         <span class="ansi-green-fg">for</span> var<span class="ansi-blue-fg">,</span> slc<span class="ansi-blue-fg">,</span> _<span class="ansi-blue-fg">,</span> _ <span class="ansi-green-fg">in</span> self<span class="ansi-blue-fg">.</span>ordering<span class="ansi-blue-fg">.</span>vmap<span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">---&gt; 52</span><span class="ansi-red-fg">             </span>apt<span class="ansi-blue-fg">[</span>slc<span class="ansi-blue-fg">]</span> <span class="ansi-blue-fg">=</span> dpt<span class="ansi-blue-fg">[</span>var<span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">.</span>ravel<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     53</span>         <span class="ansi-green-fg">return</span> apt
<span class="ansi-green-intense-fg ansi-bold">     54</span>

<span class="ansi-red-fg">KeyError</span>: &#39;p_logodds_&#39;
</pre></div></div>
</div>
<p>Once again because the gradient of <code class="docutils literal"><span class="pre">surv_sim</span></code> provides no information
to the <code class="docutils literal"><span class="pre">fmin</span></code> routine and it is only changed in a few cases, most of
which are not correct. Manually, looking at the log proability we can
see that the maximum is somewhere around <code class="docutils literal"><span class="pre">surv_sim</span></code><span class="math">\(=14\)</span> and
<code class="docutils literal"><span class="pre">p</span></code><span class="math">\(=0.7\)</span>. If we employ a non-gradient minimization, such as
<code class="docutils literal"><span class="pre">fmin_powell</span></code> (the default when discrete variables are detected), we
might be able to get a better estimate.</p>
<div class="nbinput nblast container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="k">with</span> <span class="n">model</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">s</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;p&#39;</span><span class="p">:</span><span class="mf">0.5</span><span class="p">,</span> <span class="s1">&#39;surv_sim&#39;</span><span class="p">:</span><span class="n">i</span><span class="p">}</span>
        <span class="n">map_est</span> <span class="o">=</span> <span class="n">mc</span><span class="o">.</span><span class="n">find_MAP</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="n">s</span><span class="p">,</span> <span class="nb">vars</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">vars</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;surv_sim: </span><span class="si">%i</span><span class="s1">-&gt;</span><span class="si">%i</span><span class="s1">, p: </span><span class="si">%f</span><span class="s1">-&gt;</span><span class="si">%f</span><span class="s1">, LogP:</span><span class="si">%f</span><span class="s1">&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">s</span><span class="p">[</span><span class="s1">&#39;surv_sim&#39;</span><span class="p">],</span>
                                                      <span class="n">map_est</span><span class="p">[</span><span class="s1">&#39;surv_sim&#39;</span><span class="p">],</span>
                                                      <span class="n">s</span><span class="p">[</span><span class="s1">&#39;p&#39;</span><span class="p">],</span>
                                                      <span class="n">map_est</span><span class="p">[</span><span class="s1">&#39;p&#39;</span><span class="p">],</span>
                                                      <span class="n">model</span><span class="o">.</span><span class="n">logpc</span><span class="p">(</span><span class="n">map_est</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<p>For most starting values this converges to the maximum log likelihood of
<span class="math">\(\approx -3.15\)</span>, but for particularly low starting values of
<code class="docutils literal"><span class="pre">surv_sim</span></code>, or values near <code class="docutils literal"><span class="pre">surv_sim</span></code><span class="math">\(=14\)</span> there is still
some noise. The scipy optimize package contains some more general
&#8216;global&#8217; minimization functions that we can utilize. The
<code class="docutils literal"><span class="pre">basinhopping</span></code> algorithm restarts the optimization at places near
found minimums. Because it has a slightly different interface to other
minimization schemes we have to define a wrapper function.</p>
<div class="nbinput nblast container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">bh</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span><span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">mc</span><span class="o">.</span><span class="n">starting</span><span class="o">.</span><span class="n">optimize</span><span class="o">.</span><span class="n">basinhopping</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="c1"># A `Result` object is returned, the argmin value can be in `x`</span>
    <span class="k">return</span> <span class="n">result</span><span class="p">[</span><span class="s1">&#39;x&#39;</span><span class="p">]</span>

<span class="k">with</span> <span class="n">model</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">s</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;p&#39;</span><span class="p">:</span><span class="mf">0.5</span><span class="p">,</span> <span class="s1">&#39;surv_sim&#39;</span><span class="p">:</span><span class="n">i</span><span class="p">}</span>
        <span class="n">map_est</span> <span class="o">=</span> <span class="n">mc</span><span class="o">.</span><span class="n">find_MAP</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="n">s</span><span class="p">,</span> <span class="nb">vars</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">vars</span><span class="p">,</span> <span class="n">fmin</span><span class="o">=</span><span class="n">bh</span><span class="p">)</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;surv_sim: </span><span class="si">%i</span><span class="s1">-&gt;</span><span class="si">%i</span><span class="s1">, p: </span><span class="si">%f</span><span class="s1">-&gt;</span><span class="si">%f</span><span class="s1">, LogP:</span><span class="si">%f</span><span class="s1">&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">s</span><span class="p">[</span><span class="s1">&#39;surv_sim&#39;</span><span class="p">],</span>
                                                      <span class="n">floor</span><span class="p">(</span><span class="n">map_est</span><span class="p">[</span><span class="s1">&#39;surv_sim&#39;</span><span class="p">]),</span>
                                                      <span class="n">s</span><span class="p">[</span><span class="s1">&#39;p&#39;</span><span class="p">],</span>
                                                      <span class="n">map_est</span><span class="p">[</span><span class="s1">&#39;p&#39;</span><span class="p">],</span>
                                                      <span class="n">model</span><span class="o">.</span><span class="n">logpc</span><span class="p">(</span><span class="n">map_est</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<p>By default <code class="docutils literal"><span class="pre">basinhopping</span></code> uses a gradient minimization technique,
<code class="docutils literal"><span class="pre">fmin_bfgs</span></code>, resulting in inaccurate predictions many times. If we
force <code class="docutils literal"><span class="pre">basinhoping</span></code> to use a non-gradient technique we get much better
results</p>
<div class="nbinput nblast container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="k">with</span> <span class="n">model</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">s</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;p&#39;</span><span class="p">:</span><span class="mf">0.5</span><span class="p">,</span> <span class="s1">&#39;surv_sim&#39;</span><span class="p">:</span><span class="n">i</span><span class="p">}</span>
        <span class="n">map_est</span> <span class="o">=</span> <span class="n">mc</span><span class="o">.</span><span class="n">find_MAP</span><span class="p">(</span><span class="n">start</span><span class="o">=</span><span class="n">s</span><span class="p">,</span> <span class="nb">vars</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">vars</span><span class="p">,</span> <span class="n">fmin</span><span class="o">=</span><span class="n">bh</span><span class="p">,</span> <span class="n">minimizer_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;method&quot;</span><span class="p">:</span> <span class="o">/</span><span class="s2">&quot;Powell&quot;</span><span class="p">})</span>
        <span class="k">print</span><span class="p">(</span><span class="s1">&#39;surv_sim: </span><span class="si">%i</span><span class="s1">-&gt;</span><span class="si">%i</span><span class="s1">, p: </span><span class="si">%f</span><span class="s1">-&gt;</span><span class="si">%f</span><span class="s1">, LogP:</span><span class="si">%f</span><span class="s1">&#39;</span><span class="o">%</span><span class="p">(</span><span class="n">s</span><span class="p">[</span><span class="s1">&#39;surv_sim&#39;</span><span class="p">],</span>
                                                      <span class="n">map_est</span><span class="p">[</span><span class="s1">&#39;surv_sim&#39;</span><span class="p">],</span>
                                                      <span class="n">s</span><span class="p">[</span><span class="s1">&#39;p&#39;</span><span class="p">],</span>
                                                      <span class="n">map_est</span><span class="p">[</span><span class="s1">&#39;p&#39;</span><span class="p">],</span>
                                                      <span class="n">model</span><span class="o">.</span><span class="n">logpc</span><span class="p">(</span><span class="n">map_est</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<p>Confident in our MAP estimate we can sample from the posterior, making
sure we use the <code class="docutils literal"><span class="pre">Metropolis</span></code> method for our discrete variables.</p>
<div class="nbinput nblast container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="k">with</span> <span class="n">model</span><span class="p">:</span>
    <span class="n">step1</span> <span class="o">=</span> <span class="n">mc</span><span class="o">.</span><span class="n">step_methods</span><span class="o">.</span><span class="n">HamiltonianMC</span><span class="p">(</span><span class="nb">vars</span><span class="o">=</span><span class="p">[</span><span class="n">p</span><span class="p">])</span>
    <span class="n">step2</span> <span class="o">=</span> <span class="n">mc</span><span class="o">.</span><span class="n">step_methods</span><span class="o">.</span><span class="n">Metropolis</span><span class="p">(</span><span class="nb">vars</span><span class="o">=</span><span class="p">[</span><span class="n">surv_sim</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="k">with</span> <span class="n">model</span><span class="p">:</span>
    <span class="n">trace</span> <span class="o">=</span> <span class="n">mc</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="mi">25000</span><span class="p">,[</span><span class="n">step1</span><span class="p">,</span><span class="n">step2</span><span class="p">],</span><span class="n">start</span><span class="o">=</span><span class="n">map_est</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span><span class="n">mc</span><span class="o">.</span><span class="n">traceplot</span><span class="p">(</span><span class="n">trace</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span>
</pre></div>
</div>
</div>
</div>


           </div>
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2016, John Salvatier, Christopher Fonnesbeck, Thomas Wiecki.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'3.0.rc1',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>