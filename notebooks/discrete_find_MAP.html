

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Using find_MAP on models with discrete variables &mdash; pymc3 3.0 documentation</title>
  

  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  

  

  
    <link rel="top" title="pymc3 3.0 documentation" href="../index.html"/> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> pymc3
          

          
          </a>

          
            
            
              <div class="version">
                3.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <ul>
<li class="toctree-l1"><a class="reference internal" href="../examples.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api.html">API Reference</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="../index.html">pymc3</a>
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          

 



<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../index.html">Docs</a> &raquo;</li>
      
    <li>Using <code class="docutils literal"><span class="pre">find_MAP</span></code> on models with discrete variables</li>
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/notebooks/discrete_find_MAP.txt" rel="nofollow"> View page source</a>
          
        
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput,
div.nbinput > div,
div.nbinput div[class^=highlight],
div.nbinput div[class^=highlight] pre,
div.nboutput,
div.nboutput > div,
div.nboutput div[class^=highlight],
div.nboutput div[class^=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput div[class^=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput,
div.nboutput {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
}

/* input container */
div.nbinput {
    padding-top: 5px;
}

/* last container */
div.nblast {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput > :first-child pre {
    color: #303F9F;
}

/* output prompt */
div.nboutput > :first-child pre {
    color: #D84315;
}

/* all prompts */
div.nbinput > :first-child[class^=highlight],
div.nboutput > :first-child[class^=highlight],
div.nboutput > :first-child {
    min-width: 11ex;
    padding-top: 0.4em;
    padding-right: 0.4em;
    text-align: right;
    flex: 0;
}

/* input/output area */
div.nbinput > :nth-child(2)[class^=highlight],
div.nboutput > :nth-child(2),
div.nboutput > :nth-child(2)[class^=highlight] {
    padding: 0.4em;
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}

/* input area */
div.nbinput > :nth-child(2)[class^=highlight] {
    border: 1px solid #cfcfcf;
    border-radius: 2px;
    background: #f7f7f7;
}

/* override MathJax center alignment in output cells */
div.nboutput div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.pngmath center alignment in output cells */
div.nboutput div.math p {
    text-align: left;
}

/* standard error */
div.nboutput  > :nth-child(2).stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-bold { font-weight: bold; }

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast,
.nboutput.nblast {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast + .nbinput {
    margin-top: -19px;
}

/* nice headers on first paragraph of info/warning boxes */
.admonition .first {
    margin: -12px;
    padding: 6px 12px;
    margin-bottom: 12px;
    color: #fff;
    line-height: 1;
    display: block;
}
.admonition.warning .first {
    background: #f0b37e;
}
.admonition.note .first {
    background: #6ab0de;
}
.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}
</style>
<div class="section" id="Using-find_MAP-on-models-with-discrete-variables">
<h1>Using <code class="docutils literal"><span class="pre">find_MAP</span></code> on models with discrete variables<a class="headerlink" href="#Using-find_MAP-on-models-with-discrete-variables" title="Permalink to this headline">Â¶</a></h1>
<p>Maximum a posterior(MAP) estimation, can be difficult in models which
have discrete stochastic variables. Here we demonstrate the problem with
a simple model, and present a few possible work arounds.</p>
<div class="nbinput nblast container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [1]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span>import pymc3 as mc
</pre></div>
</div>
</div>
<p>We define a simple model of a survey with one data point. We use a
<span class="math">\(Beta\)</span> distribution for the <span class="math">\(p\)</span> parameter in a binomial. We
would like to know both the posterior distribution for p, as well as the
predictive posterior distribution over the survey parameter.</p>
<div class="nbinput nblast container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [2]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span>alpha = 4
beta = 4
n = 20
yes = 15

with mc.Model() as model:
    p = mc.Beta(&#39;p&#39;, alpha, beta)
    surv_sim = mc.Binomial(&#39;surv_sim&#39;, n=n, p=p)
    surv = mc.Binomial(&#39;surv&#39;, n=n, p=p, observed=yes)
</pre></div>
</div>
</div>
<p>First let&#8217;s try and use <code class="docutils literal"><span class="pre">find_MAP</span></code>.</p>
<div class="nbinput container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [3]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span>with model:
    print(mc.find_MAP())
</pre></div>
</div>
</div>
<div class="nboutput nblast container">
<div class="container">
</div>
<div class="container">
<div class="highlight"><pre>
{&#39;p&#39;: array(0.6086956533498806)}
</pre></div></div>
</div>
<p><code class="docutils literal"><span class="pre">find_map</span></code> defaults to find the MAP for only the continuous variables
we have to specify if we would like to use the discrete variables.</p>
<div class="nbinput container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [4]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span>with model:
    print(mc.find_MAP(vars=model.vars, disp=True))
</pre></div>
</div>
</div>
<div class="nboutput nblast container">
<div class="container">
</div>
<div class="container">
<div class="highlight"><pre>
Warning: vars contains discrete variables. MAP estimates may not be accurate for the default parameters. Defaulting to non-gradient minimization fmin_powell.
Optimization terminated successfully.
         Current function value: 3.111511
         Iterations: 3
         Function evaluations: 95
{&#39;surv_sim&#39;: 14.0, &#39;p&#39;: array(0.695652178810167)}
</pre></div></div>
</div>
<p>We set the <code class="docutils literal"><span class="pre">disp</span></code> variable to display a warning that we are using a
non-gradient minimization technique, as discrete variables do not give
much gradient information. To demonstrate this, if we use a gradient
based minimization, <code class="docutils literal"><span class="pre">fmin_bfgs</span></code>, with various starting points we see
that the map does not converge.</p>
<div class="nbinput container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [5]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span>with model:
    for i in range(n+1):
        s = {&#39;p&#39;:0.5, &#39;surv_sim&#39;:i}
        map_est = mc.find_MAP(start=s, vars=model.vars, fmin=mc.starting.optimize.fmin_bfgs)
        print(&#39;surv_sim: %i-&gt;%i, p: %f-&gt;%f, LogP:%f&#39;%(s[&#39;surv_sim&#39;],
                                                      map_est[&#39;surv_sim&#39;],
                                                      s[&#39;p&#39;],
                                                      map_est[&#39;p&#39;],
                                                      model.logpc(map_est)))
</pre></div>
</div>
</div>
<div class="nboutput nblast container">
<div class="container">
</div>
<div class="container">
<div class="highlight"><pre>
surv_sim: 0-&gt;-1, p: 0.500000-&gt;0.391133, LogP:-inf
surv_sim: 1-&gt;1, p: 0.500000-&gt;0.500000, LogP:-14.298540
surv_sim: 2-&gt;2, p: 0.500000-&gt;0.500000, LogP:-12.047249
surv_sim: 3-&gt;3, p: 0.500000-&gt;0.500000, LogP:-10.255489
surv_sim: 4-&gt;4, p: 0.500000-&gt;0.500000, LogP:-8.808570
surv_sim: 5-&gt;5, p: 0.500000-&gt;0.500000, LogP:-7.645419
surv_sim: 6-&gt;6, p: 0.500000-&gt;0.500000, LogP:-6.729129
surv_sim: 7-&gt;7, p: 0.500000-&gt;0.500000, LogP:-6.035981
surv_sim: 8-&gt;8, p: 0.500000-&gt;0.500000, LogP:-5.550474
surv_sim: 9-&gt;8, p: 0.500000-&gt;0.558888, LogP:-5.161793
surv_sim: 10-&gt;9, p: 0.500000-&gt;0.587384, LogP:-4.563607
surv_sim: 11-&gt;10, p: 0.500000-&gt;0.500000, LogP:-5.167477
surv_sim: 12-&gt;11, p: 0.500000-&gt;0.500000, LogP:-5.262785
surv_sim: 13-&gt;12, p: 0.500000-&gt;0.500000, LogP:-5.550465
surv_sim: 14-&gt;13, p: 0.500000-&gt;0.500000, LogP:-6.035970
surv_sim: 15-&gt;14, p: 0.500000-&gt;0.681157, LogP:-3.133947
surv_sim: 16-&gt;16, p: 0.500000-&gt;0.500000, LogP:-8.808570
surv_sim: 17-&gt;17, p: 0.500000-&gt;0.500000, LogP:-10.255489
surv_sim: 18-&gt;18, p: 0.500000-&gt;0.500000, LogP:-12.047249
surv_sim: 19-&gt;19, p: 0.500000-&gt;0.500000, LogP:-14.298540
surv_sim: 20-&gt;20, p: 0.500000-&gt;0.500000, LogP:-17.294273
</pre></div></div>
</div>
<p>Once again because the gradient of <code class="docutils literal"><span class="pre">surv_sim</span></code> provides no information
to the <code class="docutils literal"><span class="pre">fmin</span></code> routine and it is only changed in a few cases, most of
which are not correct. Manually, looking at the log proability we can
see that the maximum is somewhere around <code class="docutils literal"><span class="pre">surv_sim</span></code><span class="math">\(=14\)</span> and
<code class="docutils literal"><span class="pre">p</span></code><span class="math">\(=0.7\)</span>. If we employ a non-gradient minimization, such as
<code class="docutils literal"><span class="pre">fmin_powell</span></code> (the default when discrete variables are detected), we
might be able to get a better estimate.</p>
<div class="nbinput container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [6]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span>with model:
    for i in range(n+1):
        s = {&#39;p&#39;:0.5, &#39;surv_sim&#39;:i}
        map_est = mc.find_MAP(start=s, vars=model.vars)
        print(&#39;surv_sim: %i-&gt;%i, p: %f-&gt;%f, LogP:%f&#39;%(s[&#39;surv_sim&#39;],
                                                      map_est[&#39;surv_sim&#39;],
                                                      s[&#39;p&#39;],
                                                      map_est[&#39;p&#39;],
                                                      model.logpc(map_est)))
</pre></div>
</div>
</div>
<div class="nboutput nblast container">
<div class="container">
</div>
<div class="container">
<div class="highlight"><pre>
surv_sim: 0-&gt;2, p: 0.500000-&gt;0.434783, LogP:-11.654827
surv_sim: 1-&gt;3, p: 0.500000-&gt;0.456522, LogP:-10.081356
surv_sim: 2-&gt;6, p: 0.500000-&gt;0.521739, LogP:-6.685637
surv_sim: 3-&gt;7, p: 0.500000-&gt;0.543478, LogP:-5.861849
surv_sim: 4-&gt;14, p: 0.500000-&gt;0.695652, LogP:-3.111511
surv_sim: 5-&gt;14, p: 0.500000-&gt;0.674290, LogP:-3.159870
surv_sim: 6-&gt;14, p: 0.500000-&gt;0.695652, LogP:-3.111511
surv_sim: 7-&gt;14, p: 0.500000-&gt;0.695652, LogP:-3.111511
surv_sim: 8-&gt;14, p: 0.500000-&gt;0.695652, LogP:-3.111511
surv_sim: 9-&gt;14, p: 0.500000-&gt;0.695652, LogP:-3.111511
surv_sim: 10-&gt;14, p: 0.500000-&gt;0.695652, LogP:-3.111511
surv_sim: 11-&gt;14, p: 0.500000-&gt;0.695652, LogP:-3.111511
surv_sim: 12-&gt;14, p: 0.500000-&gt;0.695652, LogP:-3.111511
surv_sim: 13-&gt;14, p: 0.500000-&gt;0.695652, LogP:-3.111511
surv_sim: 14-&gt;14, p: 0.500000-&gt;0.695652, LogP:-3.111511
surv_sim: 15-&gt;15, p: 0.500000-&gt;0.717392, LogP:-3.149062
surv_sim: 16-&gt;14, p: 0.500000-&gt;0.695652, LogP:-3.111511
surv_sim: 17-&gt;15, p: 0.500000-&gt;0.717391, LogP:-3.149062
surv_sim: 18-&gt;14, p: 0.500000-&gt;0.695652, LogP:-3.111511
surv_sim: 19-&gt;14, p: 0.500000-&gt;0.695652, LogP:-3.111511
surv_sim: 20-&gt;14, p: 0.500000-&gt;0.712421, LogP:-3.142725
</pre></div></div>
</div>
<p>For most starting values this converges to the maximum log likelihood of
<span class="math">\(\approx -3.15\)</span>, but for particularly low starting values of
<code class="docutils literal"><span class="pre">surv_sim</span></code>, or values near <code class="docutils literal"><span class="pre">surv_sim</span></code><span class="math">\(=14\)</span> there is still
some noise. The scipy optimize package contains some more general
&#8216;global&#8217; minimization functions that we can utilize. The
<code class="docutils literal"><span class="pre">basinhopping</span></code> algorithm restarts the optimization at places near
found minimums. Because it has a slightly different interface to other
minimization schemes we have to define a wrapper function.</p>
<div class="nbinput container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [7]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span>def bh(*args,**kwargs):
    result = mc.starting.optimize.basinhopping(*args, **kwargs)
    # A `Result` object is returned, the argmin value can be in `x`
    return result[&#39;x&#39;]

with model:
    for i in range(n+1):
        s = {&#39;p&#39;:0.5, &#39;surv_sim&#39;:i}
        map_est = mc.find_MAP(start=s, vars=model.vars, fmin=bh)
        print(&#39;surv_sim: %i-&gt;%i, p: %f-&gt;%f, LogP:%f&#39;%(s[&#39;surv_sim&#39;],
                                                      floor(map_est[&#39;surv_sim&#39;]),
                                                      s[&#39;p&#39;],
                                                      map_est[&#39;p&#39;],
                                                      model.logpc(map_est)))
</pre></div>
</div>
</div>
<div class="nboutput nblast container">
<div class="container">
</div>
<div class="container">
<div class="highlight"><pre>
surv_sim: 0-&gt;5, p: 0.500000-&gt;0.500000, LogP:-7.645419
surv_sim: 1-&gt;7, p: 0.500000-&gt;0.543478, LogP:-5.861849
surv_sim: 2-&gt;10, p: 0.500000-&gt;0.608696, LogP:-4.071797
surv_sim: 3-&gt;8, p: 0.500000-&gt;0.565217, LogP:-5.158052
surv_sim: 4-&gt;10, p: 0.500000-&gt;0.608696, LogP:-4.071797
surv_sim: 5-&gt;7, p: 0.500000-&gt;0.543478, LogP:-5.861849
surv_sim: 6-&gt;12, p: 0.500000-&gt;0.652174, LogP:-3.385867
surv_sim: 7-&gt;8, p: 0.500000-&gt;0.565217, LogP:-5.158052
surv_sim: 8-&gt;11, p: 0.500000-&gt;0.630435, LogP:-3.679320
surv_sim: 9-&gt;10, p: 0.500000-&gt;0.608696, LogP:-4.071797
surv_sim: 10-&gt;12, p: 0.500000-&gt;0.652174, LogP:-3.385867
surv_sim: 11-&gt;13, p: 0.500000-&gt;0.673913, LogP:-3.194359
surv_sim: 12-&gt;14, p: 0.500000-&gt;0.695652, LogP:-3.111511
surv_sim: 13-&gt;14, p: 0.500000-&gt;0.695652, LogP:-3.111511
surv_sim: 14-&gt;14, p: 0.500000-&gt;0.695652, LogP:-3.111511
surv_sim: 15-&gt;14, p: 0.500000-&gt;0.695652, LogP:-3.111511
surv_sim: 16-&gt;15, p: 0.500000-&gt;0.717391, LogP:-3.149062
surv_sim: 17-&gt;14, p: 0.500000-&gt;0.695652, LogP:-3.111511
surv_sim: 18-&gt;15, p: 0.500000-&gt;0.717391, LogP:-3.149062
surv_sim: 19-&gt;18, p: 0.500000-&gt;0.782609, LogP:-4.247450
surv_sim: 20-&gt;18, p: 0.500000-&gt;0.782609, LogP:-4.247450
</pre></div></div>
</div>
<p>By default <code class="docutils literal"><span class="pre">basinhopping</span></code> uses a gradient minimization technique,
<code class="docutils literal"><span class="pre">fmin_bfgs</span></code>, resulting in inaccurate predictions many times. If we
force <code class="docutils literal"><span class="pre">basinhoping</span></code> to use a non-gradient technique we get much better
results</p>
<div class="nbinput container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [8]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span>with model:
    for i in range(n+1):
        s = {&#39;p&#39;:0.5, &#39;surv_sim&#39;:i}
        map_est = mc.find_MAP(start=s, vars=model.vars, fmin=bh, minimizer_kwargs={&quot;method&quot;: /&quot;Powell&quot;})
        print(&#39;surv_sim: %i-&gt;%i, p: %f-&gt;%f, LogP:%f&#39;%(s[&#39;surv_sim&#39;],
                                                      map_est[&#39;surv_sim&#39;],
                                                      s[&#39;p&#39;],
                                                      map_est[&#39;p&#39;],
                                                      model.logpc(map_est)))
</pre></div>
</div>
</div>
<div class="nboutput nblast container">
<div class="container">
</div>
<div class="container">
<div class="highlight"><pre>
surv_sim: 0-&gt;14, p: 0.500000-&gt;0.695652, LogP:-3.111511
surv_sim: 1-&gt;14, p: 0.500000-&gt;0.695652, LogP:-3.111511
surv_sim: 2-&gt;14, p: 0.500000-&gt;0.695652, LogP:-3.111511
surv_sim: 3-&gt;14, p: 0.500000-&gt;0.695652, LogP:-3.111511
surv_sim: 4-&gt;14, p: 0.500000-&gt;0.695652, LogP:-3.111511
surv_sim: 5-&gt;14, p: 0.500000-&gt;0.695652, LogP:-3.111511
surv_sim: 6-&gt;14, p: 0.500000-&gt;0.695652, LogP:-3.111511
surv_sim: 7-&gt;14, p: 0.500000-&gt;0.695652, LogP:-3.111511
surv_sim: 8-&gt;14, p: 0.500000-&gt;0.695652, LogP:-3.111511
surv_sim: 9-&gt;14, p: 0.500000-&gt;0.695652, LogP:-3.111511
surv_sim: 10-&gt;14, p: 0.500000-&gt;0.695652, LogP:-3.111511
surv_sim: 11-&gt;14, p: 0.500000-&gt;0.695652, LogP:-3.111511
surv_sim: 12-&gt;14, p: 0.500000-&gt;0.695652, LogP:-3.111511
surv_sim: 13-&gt;14, p: 0.500000-&gt;0.695652, LogP:-3.111511
surv_sim: 14-&gt;14, p: 0.500000-&gt;0.695652, LogP:-3.111511
surv_sim: 15-&gt;14, p: 0.500000-&gt;0.695652, LogP:-3.111511
surv_sim: 16-&gt;14, p: 0.500000-&gt;0.695652, LogP:-3.111511
surv_sim: 17-&gt;14, p: 0.500000-&gt;0.695652, LogP:-3.111511
surv_sim: 18-&gt;14, p: 0.500000-&gt;0.695652, LogP:-3.111511
surv_sim: 19-&gt;14, p: 0.500000-&gt;0.695652, LogP:-3.111511
surv_sim: 20-&gt;14, p: 0.500000-&gt;0.695652, LogP:-3.111511
</pre></div></div>
</div>
<p>Confident in our MAP estimate we can sample from the posterior, making
sure we use the <code class="docutils literal"><span class="pre">Metropolis</span></code> method for our discrete variables.</p>
<div class="nbinput nblast container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [9]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span>with model:
    step1 = mc.step_methods.HamiltonianMC(vars=[p])
    step2 = mc.step_methods.Metropolis(vars=[surv_sim])
</pre></div>
</div>
</div>
<div class="nbinput container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [10]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span>with model:
    trace = mc.sample(25000,[step1,step2],start=map_est)
</pre></div>
</div>
</div>
<div class="nboutput nblast container">
<div class="container">
</div>
<div class="container">
<div class="highlight"><pre>
 [-----------------100%-----------------] 25000 of 25000 complete in 37.4 sec
</pre></div></div>
</div>
<div class="nbinput container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [11]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span>mc.traceplot(trace);
</pre></div>
</div>
</div>
<div class="nboutput nblast container">
<div class="container">
</div>
<div class="container">
<img alt="notebooks/../_build/.doctrees/nbsphinx/notebooks_discrete_find_MAP_20_0.png" src="notebooks/../_build/.doctrees/nbsphinx/notebooks_discrete_find_MAP_20_0.png" />
</div>
</div>
<div class="nbinput nblast container">
<div class="highlight-none"><div class="highlight"><pre>
<span></span>In [ ]:
</pre></div>
</div>
<div class="highlight-ipython3"><div class="highlight"><pre>
<span></span>
</pre></div>
</div>
</div>
</div>


           </div>
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2015, John Salvatier and Christopher Fonnesbeck.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'3.0',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  
  
    <script type="text/javascript" src="../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>